{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*###주의###Mecab과 KONLPY 갖춘 후에 실행 가능*\n",
        "\n"
      ],
      "metadata": {
        "id": "-HimcdPAOVqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 환경에서는 매번 새로 돌릴 때마다 위의 두 패키지 설치가 필요합니다.\n",
        "이에 아래 코드(!curl 부분)를 제외한 다른 부분만 본인의 컴퓨터 환경에서 따로 실행하시는 것을 권장합니다. (시간 여유가 되신다면 매번 설치하시고 돌리셔도 무방합니다.)"
      ],
      "metadata": {
        "id": "Z3SvLg3tPocD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
      ],
      "metadata": {
        "id": "BqiqAEDxO9xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 MECAB"
      ],
      "metadata": {
        "id": "Vlv3w8zfN0jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "Mecab = Mecab()\n",
        "\n",
        "text = '나가떨어지다'\n",
        "print(Mecab.pos(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb10C9S-NzaJ",
        "outputId": "5fcd178b-9d71-487e-cbd8-341df3a859e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('나', 'NP'), ('가', 'JKS'), ('떨어지', 'VV'), ('다', 'EC')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **HUFS_PARSER 적용 부분**"
      ],
      "metadata": {
        "id": "i0foerwUOngw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "Mecab = Mecab()\n",
        "\n",
        "def HUFS_ization(target_list):\n",
        "  #튜플->리스트화\n",
        "  output_list=[]\n",
        "  for i in range (len(target_list)):\n",
        "      pos_set = list(target_list[i])\n",
        "      output_list.append(pos_set)\n",
        "  output_list\n",
        "\n",
        "  #pos태그 바꾸기\n",
        "  for n in range (len(output_list)):\n",
        "      ###체언###\n",
        "      if 'NNG' in output_list[n][1]:\n",
        "          output_list[n][1] = 'N:co'\n",
        "      elif 'NNP' in output_list[n][1]:\n",
        "          output_list[n][1] = 'N:pr'\n",
        "      elif 'NNB' in output_list[n][1]:\n",
        "          output_list[n][1] = 'N:dep'\n",
        "      elif 'NNBC' in output_list[n][1]:\n",
        "          output_list[n][1] = 'N:uni'\n",
        "      elif 'NR' in output_list[n][1]:\n",
        "          output_list[n][1] = 'N:num'\n",
        "      elif 'NP' in output_list[n][1]:\n",
        "          output_list[n][1] = 'N:pro'\n",
        "      ###용언###\n",
        "      elif 'VV' in output_list[n][1]:\n",
        "          output_list[n][1] = 'V:v'\n",
        "      elif 'VA' in output_list[n][1]:\n",
        "          output_list[n][1] = 'V:a'\n",
        "      elif 'VX' in output_list[n][1]:\n",
        "          output_list[n][1] = 'V:aux'\n",
        "      elif 'VCP' in output_list[n][1]:\n",
        "          output_list[n][1] = '#V:a'\n",
        "      elif 'VCN' in output_list[n][1]:\n",
        "          output_list[n][1] = 'V:a'\n",
        "      ###수식언###\n",
        "      elif 'MM' in output_list[n][1]:\n",
        "          output_list[n][1] = 'Adn'\n",
        "      elif 'MAG' in output_list[n][1]:\n",
        "          output_list[n][1] = 'Adv'\n",
        "      elif 'MAJ' in output_list[n][1]:\n",
        "          output_list[n][1] = 'Con'\n",
        "      ###독립언###\n",
        "      elif 'IC' in output_list[n][1]:\n",
        "          output_list[n][1] = 'Itj'\n",
        "      ###관계언###\n",
        "      elif 'JKS' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Del:nom'\n",
        "      elif 'JKC' in output_list[n][1]:\n",
        "          output_list[n][1] = '#M:nom'\n",
        "      elif 'JKG' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Adn'\n",
        "      elif 'JKO' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Del:acc'\n",
        "      elif 'JKB' in output_list[n][1]:\n",
        "          output_list[n][1] = '#P'\n",
        "      elif 'JKV' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Voc'\n",
        "      elif 'JKQ' in output_list[n][1]:\n",
        "          output_list[n][1] = '#M:quot'\n",
        "      elif 'JX' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Del'\n",
        "      elif 'JC' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Con'\n",
        "      ###선어말어미###\n",
        "      elif 'EP' in output_list[n][1]:\n",
        "          output_list[n][1] = '-Nfs'\n",
        "      ###어말어미###\n",
        "      elif 'EF' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Se'\n",
        "      elif 'EC' in output_list[n][1]:\n",
        "          output_list[n][1] = 'Adv:s, vp, v\\', v'\n",
        "      elif 'ETN' in output_list[n][1]:\n",
        "          output_list[n][1] = '#N:s'\n",
        "      elif 'ETM' in output_list[n][1]:\n",
        "          output_list[n][1] = '#Adn:s'\n",
        "      ###접두사###\n",
        "      elif 'XPN' in output_list[n][1]:\n",
        "          output_list[n][1] = 'XP:adn-,#Adn, Adn'\n",
        "      ###접미사###\n",
        "      elif 'XSN' in output_list[n][1]:\n",
        "          output_list[n][1] = '-XS:n, #N, N'\n",
        "      elif 'XSV' in output_list[n][1]:\n",
        "          output_list[n][1] = '-XS:v, #V:v, V:v'\n",
        "      elif 'XSA' in output_list[n][1]:\n",
        "          output_list[n][1] = '-XS:a, #V:a, V:a'\n",
        "      ###어근###\n",
        "      elif 'XR' in output_list[n][1]:\n",
        "          output_list[n][1] = 'Rt'\n",
        "      ###부호###\n",
        "      elif 'SE' in output_list[n][1]:\n",
        "          output_list[n][1] = 'SR'      \n",
        "\n",
        "  return output_list\n",
        "\n",
        "text = '나가떨어지다'\n",
        "HUFS_ization(Mecab.pos(text))"
      ],
      "metadata": {
        "id": "iuG0nt0DNzxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d122009e-00d8-4de4-979e-dc65483c61bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['나', 'N:pro'], ['가', '#Del:nom'], ['떨어지', 'V:v'], ['다', \"Adv:s, vp, v', v\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수형도를 위한 작업"
      ],
      "metadata": {
        "id": "ig8W7cw7QQw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "쓸지는 모르지만 혹시 몰라서 기록해두는 용도입니다. 무시하셔도 좋습니다."
      ],
      "metadata": {
        "id": "6dVohTJ2QWyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##이후 수형도를 위한 작업입니다.(pass하셔도 됩니다.)\n",
        "def to_tuple(output_list):\n",
        "  target = output_list\n",
        "  tup_list=[]\n",
        "  for i in range (len(target)):\n",
        "      pos = tuple(target[i])\n",
        "      tup_list.append(pos)\n",
        "  return tup_list"
      ],
      "metadata": {
        "id": "RFQLfjngNzza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###수형도 작업\n",
        "import konlpy\n",
        "import nltk\n",
        "\n",
        "#POS tag a sentence\n",
        "#words = Mecab.pos(text)\n",
        "words = tup_list\n",
        "\n",
        "# Define a chunk grammar, or chunking rules, then chunk\n",
        "grammar = \"\"\"\n",
        "NP: {<N.*>*<Suffix>?}   # Noun phrase\n",
        "VP: {<V.*>*}            # Verb phrase\n",
        "AP: {<A.*>*}            # Adjective phrase\n",
        "\"\"\"\n",
        "parser = nltk.RegexpParser(grammar)\n",
        "chunks = parser.parse(words)\n",
        "print(\"# Print whole tree\")\n",
        "print(chunks.pprint())\n",
        "\n",
        "print(\"\\n# Print noun phrases only\")\n",
        "for subtree in chunks.subtrees():\n",
        "    if subtree.label()=='NP':\n",
        "        print(' '.join((e[0] for e in list(subtree))))\n",
        "        print(subtree.pprint())\n",
        "\n",
        "# Display the chunk tree\n",
        "chunks.draw()"
      ],
      "metadata": {
        "id": "0UCa3n7GNz1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JvVzrxexNz4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AowiDShXNz6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTxe8Al-Nz8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMJj2QPBUuUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}